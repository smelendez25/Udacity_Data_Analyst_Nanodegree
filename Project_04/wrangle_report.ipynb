{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 4 - Wrangle Report - Twitter Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section I - Data Gathering\n",
    "\n",
    "Project instructions were provided by Udacity team, main tasks are listed below.\n",
    "\n",
    "### Data Sources\n",
    "* Two files were provided (\"twitter-archive-enhanced.csv\" and \"image_predictions.tsv\")\n",
    "* Twitter developer account was created to gather data from twitter and store the data in a txt file called tweet_json.txt\n",
    "\n",
    "### Dataframes\n",
    "\n",
    "* twitter_data: used to load the file \"twitter-archive-enhanced.csv\".\n",
    "\n",
    "* img_pred: used to load the file \"image_predictions.tsv\"\n",
    "\n",
    "* api_data: used to store the data gathered from the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section II - Data Assesing\n",
    "\n",
    "Dataframe description is listed below.\n",
    "\n",
    "### 1 - Enhanced Twitter Archive\n",
    "The WeRateDogs Twitter archive contains basic tweet data for all 5000+ of their tweets, but not everything. One column the archive does contain though: each tweet's text, which used to extract rating, dog name, and dog \"stage\" (i.e. doggo, floofer, pupper, and puppo) to make this Twitter archive \"enhanced.\" Of the 5000+ tweets, we have filtered for tweets with ratings only (there are 2356).\n",
    "\n",
    "* tweet_id: the unique identifier for each of the tweet\n",
    "* in_reply_to_status_id: the status id for the reply given to the tweet id\n",
    "* in_reply_to_user_id: the status id for the reply given to the tweet id ( w.r.t user id)\n",
    "* timestamp: Date and time the tweet was created, in Excel-friendly format.\n",
    "* source: the web link as source\n",
    "* text: the corresponding tweets text\n",
    "* retweeted_status_id: the status id for the reply given to the tweet id i.e., for the retweeted id\n",
    "* retweeted_status_user_id: the status id for the reply given to the tweet id ( w.r.t user id) i.e., for the retweeted id\n",
    "* retweeted_status_timestamp: Date and time the tweet was created, in Excel-friendly format.\n",
    "* expanded_urls: Expanded version of url1; URL entered by user and displayed in Twitter. Note that the user-entered URL may itself be a shortened URL, e.g. from bit.ly.\n",
    "* rating_numerator: the ranking given by the user\n",
    "* rating_denominator: The reference ranking given by the user\n",
    "* name: the breed or dog's name\n",
    "* doggo, floofer, pupper, puppo -- The stage of the dog\n",
    "\n",
    "#### Quality Observations\n",
    "* not all tweets could be classified as doggo, floofer, pupper or puppo and all columns contain \"None\"\n",
    "* the source contains unnecessary HTML code\n",
    "* \"None\" was found in the name column\n",
    "* tweet_id should be a str\n",
    "* timestamp - columns should be datetime objects\n",
    "* Name column contains wrong names like \"None\", \"Bo\", \"a\", \"the\", \"an\".\n",
    "\n",
    "### 2 - Image Prediction\n",
    "WeRateDogs Twitter archive was ran through a neural network that can classify breeds of dogs. The results: a table full of image predictions (the top three only) alongside each tweet ID, image URL, and the image number that corresponded to the most confident prediction (numbered 1 to 4 since tweets can have up to four images).\n",
    "\n",
    "* tweet_id: tweet_id is the last part of the tweet URL after \"status/\"\n",
    "* jpg_url: Image link or URL\n",
    "* img_num: Image number\n",
    "* p1: p1 is the algorithm's #1 prediction for the image in the tweet\n",
    "* p1_conf: p1_conf is how confident the algorithm is in its #1 prediction\n",
    "* p1_dog: p1_dog is whether or not the #1 prediction is a breed of dog\n",
    "* p2: is the algorithm's second most likely prediction\n",
    "* p2_conf: is how confident the algorithm is in its #2 prediction\n",
    "* p2_dog: is whether or not the #2 prediction is a breed of dog\n",
    "* p3: p3 is the algorithm's #3 prediction for the image in the tweet\n",
    "* p3_conf: p3_conf is how confident the algorithm is in its #3 prediction\n",
    "* p3_dog: p3_dog is whether or not the #3 prediction is a breed of dog\n",
    "\n",
    "#### Quality Observations\n",
    "* the predicitions are sometimes lowercase, sometimes uppercase\n",
    "* there is an underscore instead of a whitespace between the words\n",
    "* there are rows with no prediciton of a dog (neither in 1, 2 nor 3)\n",
    "* the tweet_id colum should be string\n",
    "* data contains retweets\n",
    "\n",
    "### 3 - Twitter API\n",
    "In this file Tweepy was used to query Twitter's API for additional data beyond the data included in the WeRateDogs Twitter archive.\n",
    "\n",
    "* tweet_id: the unique identifier for each of the tweet\n",
    "* favorites: The count of favorites done by user\n",
    "* retweets: The count of retweets done by user\n",
    "* user_followers: The count of number of followers\n",
    "* user_favourites: The count of number of favourites\n",
    "* date_time: Date and time the tweet was created  \n",
    "\n",
    "#### Quality Observations\n",
    "* none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section III - Data Cleaning\n",
    "\n",
    "The steps below shows 8 data quality issues and 2 data tidiness issues.\n",
    "\n",
    "#### Quality Issues\n",
    "* Quality Issue # 1: In the dataframe twitter_data only 2075 tweetIds have images\n",
    "* Quality Issue # 2: In the dataframe twitter_data has some wrong or multiple URLs\n",
    "* Quality Issue # 3: In the dataframe twitter_data some dog names are listed such as (like \"a\", \"an\", \"by\", etc.)\n",
    "* Quality Issue # 4: In the dataframe twitter_data there are some tweets that were retweets from other tweets\n",
    "* Quality Issue # 5: In the dataframe img_pred some of the predictions are not dog related.\n",
    "* Quality Issue # 6: In the dataframe twitter_data the columns in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id and retweeted_status_timestamp they has several rows with missing values.\n",
    "* Quality Issue # 7: In the dataframe twitter_data the column as data type object instead of datetime64\n",
    "* Quality Issue # 8: In the dataframes twitter_data, img_pred the tweet_id has the data type int instead of string.\n",
    "\n",
    "#### Solutions\n",
    "* Quality Issue # 1: Remove the tweets without image predictions.\n",
    "* Quality Issue # 2: Using regex valid URLs will be extracted and copied into a new column.\n",
    "* Quality Issue # 3: All the names that starts with a lower case I will have no dog names\n",
    "* Quality Issue # 4: Remove the tweets that they have a tweet id in the column retweeted_status_id\n",
    "* Quality Issue # 5: In the case that the prediction is not a dog, write \"Not a dog\"\n",
    "* Quality Issue # 6: These columns contains several rows with missing values. As a result, these columns will be removed.\n",
    "* Quality Issue # 7: Change the datatype of the column timestamp to datetime64\n",
    "* Quality Issue # 8: Change the data type of the column tweet_id from int to string in all 3 dataframes\n",
    "\n",
    "#### Tidiness Issues\n",
    "* Tidiness Issue # 1: All three dataframes can be combined into one single dataframe.\n",
    "* Tidiness Issue # 2: The dog stage columns in twitter_archive can be arranged into a single column\n",
    "\n",
    "#### Solutions\n",
    "* Tidiness Issue # 1: Remove the 4 columns and put all the data in a unique column called dogo_stage\n",
    "* Tidiness Issue # 2: A new dataframe called master_file will be created with the 3 dataframes using the column tweet_id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section IV - Data Store\n",
    "\n",
    "Data was stored in csv file called \"twitter_archive_master.csv\", dimensions are: 1985 rows and 23 columns.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
